{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.ticker import MultipleLocator,FormatStrFormatter,AutoMinorLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHP=(30,30,3)\n",
    "BAND_ORDER=[2,0,1]\n",
    "BANDS=[\"F814W\",\"F125W\",\"F160W\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(a):\n",
    "    a=a-a.min()\n",
    "    a=a/a.max()\n",
    "    return a\n",
    "\n",
    "def get_angle(d):\n",
    "    fit=PCA(n_components=2).fit(\n",
    "        np.argwhere(d>=np.quantile(d,.75)))\n",
    "    return np.arctan2(*fit.components_[0])\n",
    "\n",
    "def rotation(d):\n",
    "    fl=np.apply_along_axis(max,2,d.reshape(SHP))\n",
    "    angle=get_angle(fl)\n",
    "    for i in range(0,d.shape[2]):\n",
    "        d[:,:,i]=rotate(d[:,:,i],\n",
    "                        angle/np.pi*180-90,\n",
    "                        clip=True)\n",
    "    return d\n",
    "\n",
    "def normalise_all(a,lower_q,upper_q):\n",
    "    a=a.copy()\n",
    "    x=SHP[0]*SHP[1]\n",
    "    L,U=np.quantile(a,[lower_q,upper_q])\n",
    "    a=np.clip(a,L,U)\n",
    "    for i in range(0,len(a)):\n",
    "        d=a[i,:].reshape(SHP)\n",
    "        d=rotation(d)\n",
    "        a[i,:]=d.flatten()\n",
    "    return a\n",
    "\n",
    "def get_data():\n",
    "    L=[]\n",
    "    def f(x): return re.search(\"[^/]+(?=.npy)\",x)[0]\n",
    "    fns=[x for x in map(f,glob(\"CANDELS/*.npy\"))]\n",
    "    skip=[]\n",
    "    for fn in fns:\n",
    "        x=np.load(\"CANDELS/%s.npy\" % fn,allow_pickle=True)\n",
    "        skip.append(any([x[:,:,i].max()==0 for i in range(0,SHP[2])]))\n",
    "        L.append(x.flatten())\n",
    "    a=np.row_stack(L)\n",
    "    I=(a.std(axis=1)!=0) & ~(np.array(skip))\n",
    "    return a[I],np.array(fns)[I]\n",
    "\n",
    "def get_catalog():\n",
    "    def f(x): return re.search(\"[^/]+(?=.npy)\",x)[0]\n",
    "    fns=[x for x in map(f , glob(\"CANDELS/*.npy\"))]\n",
    "    cat=pd.read_csv(\"CANDELS/catalog.csv\")\n",
    "    cat=cat[cat.ID.isin(fns)]\n",
    "    cat=cat.sort_values(\"ID\")\n",
    "    cat=cat.reset_index(drop=True)\n",
    "    return cat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def make_image(I,figsize):\n",
    "    L=[]\n",
    "    for i in I.flatten():\n",
    "        id=re.search(\"[0-9]+\",i)[0].zfill(5)\n",
    "        fn=\"GDS_RGBs/GDS_%s.png\" % id\n",
    "        if os.path.exists(fn): L.append(mpimg.imread(fn))\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    grid=ImageGrid(fig,111,nrows_ncols=figsize,axes_pad=0)\n",
    "    for ax, im in zip(grid,L):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(im)\n",
    "    plt.tight_layout()\n",
    "    return plt\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "def make_image_pre(X,figsize,title=None):\n",
    "    L=[]\n",
    "    for i in range(0,len(X)):\n",
    "        L.append(X[i,:].reshape(SHP))\n",
    "    fig=plt.figure(figsize=figsize)\n",
    "    if not title is None: fig.suptitle(title, fontsize=14)\n",
    "    grid=ImageGrid(fig,111,nrows_ncols=figsize,axes_pad=0)\n",
    "    for ax, im in zip(grid,L):\n",
    "        r=im[:,:,0]; r-=r.min()\n",
    "        if r.max()!=0: r/=r.max()\n",
    "        g=im[:,:,1]; g-=g.min()\n",
    "        if g.max()!=0: g/=g.max()\n",
    "        b=im[:,:,2]; b-=b.min()\n",
    "        if b.max()!=0: b/=b.max()\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(np.dstack([g,r,b]))\n",
    "    #plt.tight_layout(h_pad=10)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data,indexes=get_data()\n",
    "norm_data=normalise_all(raw_data,0,.99)\n",
    "print(\"size\",len(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(.96).fit(norm_data)\n",
    "scores=pca.transform(norm_data)\n",
    "lik=pca.score_samples(norm_data)\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[0,6,10,11,24,33,43,45,50]\n",
    "n=norm_data[examples]\n",
    "make_image_pre(n,(3,3))\n",
    "plt.suptitle(\"original\", fontsize=14)\n",
    "plt.savefig(\"recon/recon0.png\")\n",
    "for k in [2,4,8,16,32,64,128,256,512,1024,2048]:\n",
    "    print(\"k\",k)\n",
    "    p=PCA(k).fit(norm_data)\n",
    "    s=p.inverse_transform(p.transform(n))\n",
    "    fn=\"recon/recon%d.png\" % k\n",
    "    make_image_pre(s,(3,3),\"k=%s\" % k).savefig(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=12\n",
    "L=[];M=[]\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "print(pca.explained_variance_ratio_[0])\n",
    "for i in range(0,1000):\n",
    "    print(i)\n",
    "    idx=np.random.choice(range(0,len(norm_data)),int(.7*len(norm_data)),replace=False)\n",
    "    p=PCA(k).fit(norm_data[idx])\n",
    "    L.append(np.sum(p.explained_variance_ratio_))\n",
    "    M.append(p.explained_variance_ratio_[0])\n",
    "_=plt.hist(L)\n",
    "plt.ylabel(\"# Occurrences\", fontsize=14)\n",
    "plt.xlabel(\"Explained Variance Ratio\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\")\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"bootstrap12.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "_=plt.hist(M,color=\"gray\",bins=20)\n",
    "plt.ylabel(\"# Occurrences\", fontsize=14)\n",
    "plt.xlabel(\"Explained Variance Ratio\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\")\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"bootstrap1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lik_idx=indexes[np.argsort(lik)]\n",
    "P=make_image(lik_idx[0:25],(5,5))\n",
    "P.tight_layout()\n",
    "P.savefig(\"most-rare.png\")\n",
    "P=make_image(np.flip(lik_idx)[0:25],(5,5))\n",
    "P.tight_layout()\n",
    "P.savefig(\"least-rare.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample size, eigengalaxies, and explained variance contour plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "pca_n=40\n",
    "for s in range(1000,10400,200):\n",
    "    idx=np.random.choice(range(0,len(norm_data)),s,replace=False)\n",
    "    for r in range(0,100):\n",
    "        p=PCA(pca_n).fit(norm_data[idx])\n",
    "        for n in range(0,pca_n):\n",
    "            L.append(dict(n=n,s=s,r=r,v=np.cumsum(p.explained_variance_ratio_)[n]))\n",
    "X=pd.DataFrame(L)\n",
    "X.n=X.n+1\n",
    "X=X.groupby([\"s\",\"n\"]).median()\n",
    "X=X.reset_index()\n",
    "del X[\"r\"]\n",
    "X=X.pivot('s', 'n')\n",
    "x=X.columns.levels[1].values\n",
    "y=X.index.values\n",
    "z=X.values\n",
    "Xi,Yi = np.meshgrid(x, y)\n",
    "lvls=[.94,.95,.96,.97,.98,.99]\n",
    "xx=plt.contour(Yi,Xi,z,levels=lvls,colors=\"black\")\n",
    "xx.clabel(xx.levels)\n",
    "plt.ylabel(\"Eigengalaxies\", fontsize=14)\n",
    "plt.xlabel(\"Sample size\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\")\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"pca-over-samples.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative sum of explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,pca.n_components_+1),\n",
    "         np.cumsum(pca.explained_variance_ratio_),\n",
    "         color=\"black\")\n",
    "plt.ylabel(\"Explained Variance Ratio\", fontsize=14)\n",
    "plt.xlabel(\"Eigengalaxies\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\")\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"cum-var.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_data=np.dot(scores,pca.components_)+pca.mean_\n",
    "idx=(norm_data!=0)\n",
    "sm=norm_data.sum(axis=1)\n",
    "df=(norm_data-recon_data).sum(axis=1)\n",
    "sse=df/sm\n",
    "sse=sse[(sse<=.05) & (sse>=-.05)]\n",
    "print(((sse>=-.025) & (sse<=.025)).sum() / len(sse))\n",
    "plt.hist(sse,color=\"gray\",bins=100)\n",
    "plt.xlabel(\"Fractional difference\", fontsize=14)\n",
    "plt.ylabel(\"Number of objects\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\")\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\",which='minor')\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"flux-diff-hist.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Eigengalaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=[]\n",
    "N=pca.n_components_\n",
    "for i in range(0,N):\n",
    "    comp=pca.components_[i]\n",
    "    comp=comp.reshape(SHP)\n",
    "    mn=comp.min();mx=comp.max()\n",
    "    for j in BAND_ORDER: L.append((mn,mx,comp[:,:,j]))\n",
    "fig=plt.figure(figsize=(N,3*5))\n",
    "grid=ImageGrid(fig,111,nrows_ncols=(N,3),axes_pad=0)\n",
    "for i,b in enumerate(BANDS): grid[i].set_title(b)\n",
    "for ax, tup in zip(grid,L):\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    mn,mx,im=tup\n",
    "    ax.imshow(im,cmap=\"gray\", aspect=\"auto\",vmin=mn,vmax=mx)\n",
    "#plt.savefig(\"components.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyppca import ppca\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "np.random.seed(22)\n",
    "cens_data=norm_data.copy()\n",
    "miss_rows_idx=np.random.choice(indexes,int(len(norm_data)/20),replace=False)\n",
    "for i in miss_rows_idx:\n",
    "    d=cens_data[indexes==i].copy().reshape(SHP)\n",
    "    off=np.random.choice([0,1,2],1)\n",
    "    d[:,:,off]=np.nan\n",
    "    cens_data[indexes==i]=d.flatten()\n",
    "C,ss,M,X,y_ppca=ppca(cens_data,10,False)\n",
    "inc_idx=np.isin(indexes,miss_rows_idx)\n",
    "y_ppca=y_ppca[inc_idx]\n",
    "real_sum=norm_data[inc_idx].sum(axis=1)\n",
    "y_ppca_del=(norm_data[inc_idx]-y_ppca).sum(axis=1)\n",
    "y_ppca_res=y_ppca_del/real_sum\n",
    "less10=((y_ppca_res>=-.1)&(y_ppca_res<=.1)).sum()/len(y_ppca_res)\n",
    "print(\"within 10%\",less10) \n",
    "\n",
    "plt.hist(y_ppca_res,bins=100,color=\"gray\")\n",
    "plt.xlabel(\"Fractional difference\", fontsize=14)\n",
    "plt.ylabel(\"Number of objects\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\")\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True, direction=\"in\",which='minor')\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"recovery-pca.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_samp=norm_data[inc_idx]\n",
    "cens_samp=cens_data[inc_idx]\n",
    "miss_rows_samp=np.random.choice(range(0,len(norm_samp)),20,replace=False)\n",
    "for i in miss_rows_samp:\n",
    "    L=[]\n",
    "    x0=norm_samp[i].reshape(SHP)\n",
    "    x1=cens_samp[i].reshape(SHP)\n",
    "    x2=y_ppca[i].reshape(SHP)\n",
    "    mn=x0.min();mx=x0.max()\n",
    "    for k in BAND_ORDER: L.append(x0[:,:,k])\n",
    "    for k in BAND_ORDER: L.append(x1[:,:,k])\n",
    "    for k in BAND_ORDER: L.append(x2[:,:,k])\n",
    "    fig=plt.figure(figsize=(3*2,3*2))\n",
    "    grid=ImageGrid(fig,111,nrows_ncols=(3,3),axes_pad=0)\n",
    "    for i,b in enumerate(BANDS): grid[i].set_title(b)\n",
    "    for ax, im in zip(grid,L):\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.imshow(im,cmap=\"gray\",aspect=\"auto\",vmin=mn,vmax=mx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example generator for image queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "for z in range(0,150):\n",
    "    ref_id=np.random.choice(range(0,len(scores)),1)\n",
    "    ref=scores[ref_id]\n",
    "    D=(((scores-ref)**2)**.5).sum(axis=1)\n",
    "    D=pd.DataFrame(dict(v=D,i=indexes))\n",
    "    D=D.sort_values(\"v\").head(9)\n",
    "    make_image(D.i.values,(3,3)).savefig(\"nn/%d.png\" % z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity Propagation Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "clust=AffinityPropagation(damping=0.9,convergence_iter=100,max_iter=1000)\n",
    "clust=clust.fit(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "l=clust.labels_\n",
    "G=pd.DataFrame(dict(l=l)).groupby(\"l\").l.count()\n",
    "df=pd.DataFrame(dict(l=G.index,cnt=G.values))\n",
    "df=df.sort_values(\"cnt\",ascending=False)\n",
    "df=df.head(100)\n",
    "\n",
    "print(\"labels\",len(np.unique(l)))\n",
    "print(\"min\",np.min(G))\n",
    "print(\"max\",np.max(G))\n",
    "print(\"mean\",np.median(G))\n",
    "print(\"median\",np.median(G))\n",
    "\n",
    "for _,r in df.iterrows():\n",
    "    print(r.l,int(r.cnt/10)+1)\n",
    "    make_image(indexes[l==r.l],(int(r.cnt/10)+1,10)).savefig(\"clustering/%d.png\" % r.l)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
